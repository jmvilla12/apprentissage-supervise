{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25aad299",
   "metadata": {},
   "source": [
    "## TRNU.CSN: Supervised Classification TP2 2025\n",
    "\n",
    "Gilles Vanwormhoudt, Christelle Garnier, Vincent Itier, Juan-Manuel Miramont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc500f9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3717f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#TODO ADD other needed libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663c31a",
   "metadata": {},
   "source": [
    "## Data Set Information\n",
    "\n",
    "This is perhaps the best known database to be found in the pattern recognition literature. Fisherâ€™s\n",
    "paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for\n",
    "example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of\n",
    "iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable\n",
    "from each other. The predicted attribute (the output) is the class of iris plant.\n",
    "\n",
    "### Features Information\n",
    "\n",
    "1. sepal length in cm\n",
    "1. sepal width in cm\n",
    "1. petal length in cm\n",
    "1. petal width in cm\n",
    "1. classes: Iris Setosa, Iris Versicolour, Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956dd3",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "The purpose of this practical assignment is to implement the Perceptron, which is a basic supervised learning algorithm for performing binary data classification.\n",
    "\n",
    "This practical assignment consists of four parts: __implementation__, __validation__, __evaluation__, and __comparison__. The __comparison__ part is homework to be completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9840f120",
   "metadata": {},
   "source": [
    "### 1. Implementation\n",
    "\n",
    "#### Reminders\n",
    "The Perceptron algorithm is a supervised classification algorithm invented by Rosenblatt for binary classification problems (two classes). The principle of this algorithm is to find a linear classifier on a training set $S= \\{(x^{j}, y^{j})\\}$ where the inputs $x$ are vectors of dimension $d$ and the outputs $y$ are integers $\\in \\{-1,1\\}$. As explained in class, the goal is to obtain as few misclassified examples as possible.</br>\n",
    "Learning is performed using an iterative algorithm in which an example is chosen randomly from $S$ and the coefficients of the hyperplane (vector $w$ of dimension $d$ and real $w_0$) are updated if the classifier gives a wrong prediction for the chosen example. The rule for updating the coefficients is to move in the direction of the misclassified example by adding the vector of the misclassified example multiplied by a learning step to the current coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1e795",
   "metadata": {},
   "source": [
    "#### 1.1 Algorithm\n",
    "\n",
    "Implementing this algorithm requires manipulating vectors and performing simple vector calculations (addition, subtraction, and multiplication of vectors). Using the `numpy` library is therefore recommended.\n",
    "\n",
    "To implement the algorithm in Python and make it easily reusable, we can draw inspiration from the Scikit-Learn library that we learn to use during the previous practical work. In this library, supervised classifiers are implemented as object classes equipped with the special method `__init__`, which allows parameters to be provided when the classifier object is created, and two main methods: the `fit` method, which performs the learning, and the `predict` method, which performs the prediction based on the learned model.\n",
    "\n",
    "1. Write the code for a __Perceptron__ class in a file that you can call `perceptron.py`.</br>\n",
    "Since the algorithm must be applied to different situations, several parameters must be taken into account, namely:\n",
    "    - dimension: the size of the input vectors,\n",
    "    - max_iter: the maximum number of iterations of the algorithm,\n",
    "    - learning_rate: the learning rate of the algorithm.\n",
    "    \n",
    "As in Scikit-Learn, we recommend providing these parameters when creating the classifier object. You must therefore specify these parameters in the class's special `__init__` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c70542f",
   "metadata": {},
   "source": [
    "2. You must also write the code for the following two methods:\n",
    "    - The method `fit(X,y)` performs learning based on the training data $X$ and $y$. The two parameters $X$ and $y$ are lists of the same size: $X$ is a list of *numpy* vectors, $y$ is a list of integer values equal to $-1$ or $+1$. This method does not return a result; it updates the coefficients of the hyperplane (vector $w$ and real number $w_0$).\n",
    "    - The `predict(X)` method, which predicts the class for a new input $x$. The parameter $x$}$ is a *numpy* vector with the same dimensions as the training data $X$. This method returns the predicted value for the data ($-1$ or $+1$). It is also possible to consider an iterative version of this method that takes a list of data as input and returns the list of corresponding predictions.\n",
    "\n",
    "It is of course possible to add other methods to this class for factorization or structuring purposes in the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5ac8b",
   "metadata": {},
   "source": [
    "3. To fully understand how objects of this class can be used, here is an example of a Python session that creates an instance and uses the `fit` and `predict` methods for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b52d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perceptron import Perceptron\n",
    "\n",
    "# creation des donnees apprentissage\n",
    "X_train = []\n",
    "X_train.append(np.array([1, 1]))\n",
    "X_train.append(np.array([1, 0]))\n",
    "X_train.append(np.array([0, 1]))\n",
    "X_train.append(np.array([0, 0]))\n",
    "\n",
    "y_train = np.array([1, -1, -1, -1])\n",
    "\n",
    "# creation et entrainement du classifieur\n",
    "perceptron = Perceptron(dimension=2, max_iter=100, learning_rate=0.1)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "new_x = np.array([1, 1])\n",
    "print(perceptron.predict(new_x))\n",
    "\n",
    "new_x = np.array([0, 1])\n",
    "print(perceptron.predict(new_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ffe0b",
   "metadata": {},
   "source": [
    "### 2. Algorithm Validation\n",
    "\n",
    "To validate your algorithm, you can use the iris dataset. In this case, since the classifier is binary, we will limit ourselves to two species: Setosa and Versicolor. To visualize the data, we will limit ourselves to two characteristics: sepal length and petal length.\n",
    "\n",
    "1. Load the dataset as a pandas Dataframe.\n",
    "1. Extract usefull content for the validation.\n",
    "1. Display the new dataset. By examining the plot, you will see that the selected data are linearly separable.\n",
    "1. Train the perceptron. To do this, you must separate the data into a training set and a test set. Using the `train_test_split` command from *Scikit-Learn*.\n",
    "1. Test the perceptron on the test set and compare it with true labels, using `classification_report`.\n",
    "1. Construct a new visualization of the data with the line separating the two classes, whose parameters are to be determined based on the perceptron coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18a6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcabd8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f61facf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7911401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1fccea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90fd4b3e",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "\n",
    "1. Using cross validation, assess the performance of your model with several metrics form `sklearn.metrics` such as `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, ...\n",
    "1. What performances can we expect on the whole dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5289bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01df9e12",
   "metadata": {},
   "source": [
    "### 4. Comparison with other algorithm\n",
    "\n",
    "In general, it is not easy to find the classification algorithm that will give the best results with your dataset. It is often necessary to try several algorithms and several hyperparameter configurations and compare the accuracy of the corresponding models. The objective of this last part is to compare some algorithms and fine tune parameters.\n",
    "\n",
    "1. Compare your performances with the scikit-learn implementation of the perceptron, and other models.\n",
    "1. Using the `GridSearchCV` from `sklearn.model_selection`, find the best parameter for some models. Display results using the method `cv_results_.keys()` What does the function do to find the best parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c62fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91370f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ba024d2",
   "metadata": {},
   "source": [
    "### 5.  Saving the trained model\n",
    "\n",
    "Once you have found a good model for your problem, you need to think about putting it into production in an application. This involves saving the trained model and checking that it loads correctly so that it can make predictions with new data in the production system.\n",
    "\n",
    "A model produced with the Scikit library can be saved using the object serialization library called `pickle`. This library has the functions `dump()` and `load()` to save and load the model, respectively. Review the documentation for these functions to learn about their parameters and apply them in your previous work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed36b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
